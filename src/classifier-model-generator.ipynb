{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Circle\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pickle\n",
    "import loadnotebook\n",
    "from predictionhelper import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = [x for x in range(1, 34)]\n",
    "sets.remove(9)\n",
    "sets.remove(12)\n",
    "sets.remove(17)\n",
    "sets.remove(18)\n",
    "sets.remove(19)\n",
    "demo_config = {6 : sets}\n",
    "\n",
    "df_data = get_data(config=demo_config, pure=True, refresh=False).reset_index(drop=True)\n",
    "print(len(df_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pci_data = df_data[df_data[\"PCI\"].isin(whitelist_PCI)]\n",
    "size = len(pci_data)\n",
    "print(\"outlier pci\", len(df_data) - size)\n",
    "\n",
    "beam_columns = [c for c in df_data if \"beam\" in c]\n",
    "pci_data = pci_data.drop([\"RSRP\", \"RSRQ\", \"SNR\"]+beam_columns, axis=1)\n",
    "\n",
    "pci_data = pci_data.drop_duplicates()\n",
    "print(\"duplicates pci\", size - len(pci_data))\n",
    "pci_data = pci_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pci_train, pci_test = pd.DataFrame(), pd.DataFrame()\n",
    "pci_train_dict, pci_test_dict = {}, {}\n",
    "for p in demo_config :\n",
    "    for s in demo_config[p] :\n",
    "        a, b = train_test_split(pci_data[pci_data.set==s], test_size=0.3, random_state=32)\n",
    "        pci_train = pci_train.append(a)\n",
    "        pci_test = pci_test.append(b)  \n",
    "        pci_train_dict[(p, s)] = a\n",
    "        pci_test_dict[(p, s)] = b\n",
    "print(len(pci_train), len(pci_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pci_train = pci_train.drop([\"PCI\"], axis=1)\n",
    "y_pci_train = np.array(pci_train.PCI.apply(lambda x : pci_encode[x]).values.tolist())\n",
    "x_pci_test = pci_test.drop([\"PCI\"], axis=1)\n",
    "y_pci_test = np.array(pci_test.PCI.apply(lambda x : pci_encode[x]).values.tolist())\n",
    "\n",
    "x_pci_train_dict, y_pci_train_dict, x_pci_test_dict, y_pci_test_dict = {}, {}, {}, {}\n",
    "for p in demo_config :\n",
    "    for s in demo_config[p] :\n",
    "        a, b = pci_train_dict[(p,s)], pci_test_dict[(p,s)]\n",
    "        x_pci_train_dict[(p, s)] = a.drop([\"PCI\"], axis=1)\n",
    "        y_pci_train_dict[(p, s)] = np.array(a.PCI.apply(lambda x : pci_encode[x]).values.tolist())\n",
    "        x_pci_test_dict[(p, s)] = b.drop([\"PCI\"], axis=1)\n",
    "        y_pci_test_dict[(p, s)] = np.array(b.PCI.apply(lambda x : pci_encode[x]).values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_params = {'random_state':0}\n",
    "model = svm.LinearSVC(**svm_params)\n",
    "model.fit(x_pci_train, y_pci_train)\n",
    "\n",
    "y_pci_pred = model.predict(x_pci_test)\n",
    "predictions = [round(value) for value in y_pci_pred]\n",
    "accuracy = accuracy_score(y_pci_test, predictions)\n",
    "print(1-accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class knn_target :\n",
    "    def __init__(self, x_train, y_train, x_test, y_test) :\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        self.weights = ['uniform', 'distance']\n",
    "        self.algorithms = ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "        \n",
    "    def clean_param(self, param) :\n",
    "        params = {'n_neighbors':7}\n",
    "        params['weights'] = self.weights[int(param['weight'])]\n",
    "        params['algorithm'] = self.algorithms[int(param['algorithm'])]\n",
    "        params['leaf_size'] = int(param['leaf_size'])\n",
    "        params['p'] = int(param['p'])\n",
    "        return params\n",
    "        \n",
    "    def evaluate(self, weight, algorithm, leaf_size=100, p=2):\n",
    "        params = {}\n",
    "        params['weight'] = weight\n",
    "        params['algorithm'] = algorithm\n",
    "        params['leaf_size'] = int(leaf_size)\n",
    "        params['p'] = int(p)\n",
    "        params = self.clean_param(params)\n",
    "\n",
    "        model = KNeighborsClassifier(**params)\n",
    "        model.fit(self.x_train, self.y_train)\n",
    "        y_pci_pred = model.predict(self.x_test)\n",
    "        predictions = [round(value) for value in y_pci_pred]\n",
    "        accuracy = accuracy_score(self.y_test, predictions)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kt = knn_target(x_pci_train[location_col], y_pci_train, \n",
    "#                 x_pci_test[location_col], y_pci_test)\n",
    "# kBO = BayesianOptimization(kt.evaluate, {'weight': (0, 1),\n",
    "#                                         'algorithm' : (0, 3),\n",
    "#                                         'leaf_size' : (5, 50),\n",
    "#                                         'p': (1, 2),},\n",
    "#                             random_state = 1)\n",
    "\n",
    "# kBO.maximize(init_points=20, n_iter=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = kt.clean_param(kBO.res['max']['max_params'])\n",
    "# params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_params = {'n_neighbors': 7,\n",
    " 'weights': 'uniform',\n",
    " 'algorithm': 'kd_tree',\n",
    " 'leaf_size': 49,\n",
    " 'p': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(**knn_params)\n",
    "model.fit(x_pci_train, y_pci_train)\n",
    "\n",
    "y_pci_pred = model.predict(x_pci_test)\n",
    "predictions = [round(value) for value in y_pci_pred]\n",
    "accuracy = accuracy_score(y_pci_test, predictions)\n",
    "print(1-accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class xgboost_target :\n",
    "    def __init__(self, x_train, y_train, x_test, y_test) :\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        \n",
    "    def clean_param(self, param) :\n",
    "        booster_dict = {1:'gbtree', 2:'gblinear', 3:'dart'}\n",
    "        params = {'base_score':0.5, 'booster':'gbtree', 'missing':None, 'n_estimators':100, \n",
    "                  'n_jobs':1, 'objective':'multi:softmax', 'random_state':1, \n",
    "                  'reg_lambda':1, 'alpha':0, 'scale_pos_weight':1, \n",
    "                  'subsample':1, 'colsample_bytree':1, 'colsample_bylevel':1}\n",
    "\n",
    "        params['learning_rate'] = param['learning_rate']/100\n",
    "        params['booster'] = booster_dict[int(param['booster'])]\n",
    "        params['gamma'] = param['gamma']\n",
    "        params['max_depth'] = int(param['max_depth'])\n",
    "        params['min_child_weight'] = int(param['min_child_weight'])\n",
    "        params['max_delta_weight'] = int(param['max_delta_weight'])\n",
    "        params['rate_drop'] = param['rate_drop']\n",
    "        return params\n",
    "        \n",
    "    def evaluate(self, learning_rate, booster, gamma, max_depth,  \n",
    "                     min_child_weight, max_delta_weight, rate_drop):\n",
    "\n",
    "        params = {}\n",
    "        params['learning_rate'] = learning_rate\n",
    "        params['booster'] = booster\n",
    "        params['gamma'] = gamma\n",
    "        params['max_depth'] = max_depth\n",
    "        params['min_child_weight'] = min_child_weight\n",
    "        params['max_delta_weight'] = max_delta_weight\n",
    "        params['rate_drop'] = rate_drop\n",
    "        params = self.clean_param(params)\n",
    "\n",
    "        xgb_model = XGBClassifier(**params)\n",
    "        xgb_model.fit(self.x_train, self.y_train)\n",
    "        y_pci_pred = xgb_model.predict(self.x_test)\n",
    "        predictions = [round(value) for value in y_pci_pred]\n",
    "        accuracy = accuracy_score(self.y_test, predictions)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xt = xgboost_target(x_pci_train, y_pci_train, x_pci_test, y_pci_test)\n",
    "# xgbBO = BayesianOptimization(xt.xgb_evaluate, {'learning_rate': (1, 12),\n",
    "#                                             'booster' : (1, 3),\n",
    "#                                             'gamma' : (0, 50),\n",
    "#                                             'max_depth': (3, 12),\n",
    "#                                             'min_child_weight': (1, 1),\n",
    "#                                             'max_delta_weight': (1, 20),\n",
    "#                                             'rate_drop': (0, 1)},\n",
    "#                             random_state = 1)\n",
    "\n",
    "# xgbBO.maximize(init_points=10, n_iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = xt.clean_param(xgbBO.res['max']['max_params'])\n",
    "# xgb_model = XGBClassifier(**params)\n",
    "# xgb_model.fit(x_pci_train, y_pci_train)\n",
    "\n",
    "# y_pci_pred = xgb_model.predict(x_pci_test)\n",
    "# predictions = [round(value) for value in y_pci_pred]\n",
    "# accuracy = accuracy_score(y_pci_test, predictions)\n",
    "# print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_params = {'learning_rate' : 0.03, 'max_depth' : 9, 'min_child_weight':1, 'gamma':4.2522, \n",
    "                  'max_delta_weight':11}\n",
    "xgb_model = XGBClassifier(**xgboost_params)\n",
    "xgb_model.fit(x_pci_train, y_pci_train)\n",
    "\n",
    "y_pci_pred = xgb_model.predict(x_pci_test)\n",
    "predictions = [round(value) for value in y_pci_pred]\n",
    "accuracy = accuracy_score(y_pci_test, predictions)\n",
    "print(1-accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lgbm_target :\n",
    "    def __init__(self, x_train, y_train, x_test, y_test) :\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        \n",
    "    def clean_param(self, param) :\n",
    "        params = {'boosting_type':'gbdt', 'class_weight':None, 'colsample_bytree':1.0, \n",
    "                  'importance_type':'split', \n",
    "                  'min_child_samples':20, 'min_split_gain':0.0, 'n_estimators':100, 'objective':None,\n",
    "                  'random_state':0, 'reg_alpha':0.0, 'reg_lambda':0.0, 'silent':True,\n",
    "                  'subsample':1.0, 'subsample_for_bin':200000, 'subsample_freq':0}\n",
    "        params['num_leaves'] = int(param['num_leaves'])\n",
    "        params['min_child_weight'] = int(param['min_child_weight'])\n",
    "        params['max_depth'] = int(param['max_depth'])\n",
    "        params['learning_rate'] = param['learning_rate'] / 100\n",
    "        return params\n",
    "        \n",
    "    def evaluate(self, min_child_weight, learning_rate, max_depth, num_leaves):\n",
    "        params = {'num_leaves':num_leaves, \n",
    "                  'min_child_weight':min_child_weight, \n",
    "                  'max_depth':max_depth, \n",
    "                  'learning_rate':learning_rate}\n",
    "        \n",
    "        params = self.clean_param(params)\n",
    "\n",
    "        lgbm_model = LGBMClassifier(**params )\n",
    "        lgbm_model.fit(self.x_train, self.y_train)\n",
    "        y_pci_pred = lgbm_model.predict(self.x_test)\n",
    "        predictions = [round(value) for value in y_pci_pred]\n",
    "        accuracy = accuracy_score(self.y_test, predictions)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lt = lgbm_target(x_pci_train, y_pci_train, x_pci_test, y_pci_test)\n",
    "# lgbmBO = BayesianOptimization(lt.lgbm_evaluate, {'min_child_weight': (0.01, 1),\n",
    "#                                               'learning_rate': (1, 10),\n",
    "#                                               'max_depth': (-1, 15),\n",
    "#                                               'num_leaves': (5, 50)}, \n",
    "#                              random_state=3)\n",
    "\n",
    "# lgbmBO.maximize(init_points=3, n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = lt.clean_param(lgbmBO.res['max']['max_params'])\n",
    "# lgbm_model = LGBMClassifier(**params )\n",
    "# lgbm_model.fit(x_pci_train, y_pci_train)\n",
    "# y_pci_pred = lgbm_model.predict(x_pci_test)\n",
    "# predictions = [round(value) for value in y_pci_pred]\n",
    "# accuracy = accuracy_score(y_pci_test, predictions)\n",
    "# print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params = {'learning_rate' : 0.099387, 'max_depth' : 14, 'min_child_weight':0, 'num_leaves':5}\n",
    "lgbm_model = LGBMClassifier(**lgbm_params)\n",
    "lgbm_model.fit(x_pci_train, y_pci_train)\n",
    "y_pci_pred = lgbm_model.predict(x_pci_test)\n",
    "predictions = [round(value) for value in y_pci_pred]\n",
    "accuracy = accuracy_score(y_pci_test, predictions)\n",
    "print(1-accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrmse_matrix = np.empty((4, 3, 34))\n",
    "nrmse_matrix[:] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def reset_model(model_name, params=None) :\n",
    "    if 'xgb' in model_name :\n",
    "        return XGBClassifier(**xgboost_params) if params is None else XGBClassifier(**params)\n",
    "    elif 'knn' in model_name :\n",
    "        return KNeighborsClassifier(**knn_params)\n",
    "    elif 'svm' in model_name :\n",
    "        return svm.LinearSVC(**svm_params) if params is None else svm.LinearSVC(**params)\n",
    "    else :\n",
    "        return LGBMClassifier(**lgbm_params) if params is None else LGBMClassifier(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_list = ['xgboost', 'lgbm', 'knn', 'svm']\n",
    "model_idx = 0\n",
    "model_name = model_name_list[model_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = reset_model(model_name)\n",
    "model.fit(x_pci_train, y_pci_train)\n",
    "\n",
    "for s in demo_config[6] :\n",
    "    y_pred = model.predict(x_pci_test_dict[(6, s)])\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    err = 1-accuracy_score(y_pci_test_dict[(p, s)], predictions)\n",
    "    nrmse_matrix[model_idx, 0, s] = err\n",
    "    \n",
    "pickle.dump(model, open(\"db/%s_%s_baseline.pickle.dat\" % ('PCI', model_name), \"wb\"))\n",
    "for x in nrmse_matrix[model_idx, 0, 1:]:\n",
    "    print('%.3f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Independent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for s in demo_config[6] :\n",
    "    model = reset_model(model_name)\n",
    "    model.fit(x_pci_train_dict[(6, s)], y_pci_train_dict[(6, s)])\n",
    "\n",
    "    y_pred = model.predict(x_pci_test_dict[(6, s)])\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    err = 1-accuracy_score(y_pci_test_dict[(6, s)], predictions)\n",
    "    nrmse_matrix[model_idx, 1, s] = err\n",
    "    \n",
    "    pickle.dump(model, open(\"db/%s_%s_independent_set_%s.pickle.dat\" % ('PCI', model_name, s), \"wb\"))\n",
    "\n",
    "for x in nrmse_matrix[model_idx, 1, 1:]:\n",
    "    print('%.3f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for s in demo_config[6] :\n",
    "    curr_x_pci_train = pci_data[pci_data.set!=s].drop(['PCI', 'set'], axis=1)\n",
    "    curr_y_pci_train = pci_data[pci_data.set!=s].PCI.apply(lambda x : pci_encode[x]).values.tolist()\n",
    "    \n",
    "#     Testing 100%\n",
    "#     curr_x_pci_test = pci_data[pci_data.set==s].drop(['PCI', 'set'], axis=1)\n",
    "#     curr_y_pci_test = pci_data[pci_data.set==s].PCI.apply(lambda x : pci_encode[x]).values.tolist()\n",
    "#     Testing 30%\n",
    "    curr_x_pci_test = x_pci_test_dict[(6, s)]\n",
    "    curr_y_pci_test = y_pci_test_dict[(6, s)]\n",
    "    curr_x_pci_test = curr_x_pci_test.drop(['set'], axis=1)\n",
    "\n",
    "    model = reset_model(model_name)\n",
    "    model.fit(curr_x_pci_train, curr_y_pci_train)\n",
    "\n",
    "    y_pred = model.predict(curr_x_pci_test)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    err = 1-accuracy_score(curr_y_pci_test, predictions)\n",
    "    nrmse_matrix[model_idx, 2, s] = err\n",
    "    \n",
    "    pickle.dump(model, open(\"db/%s_%s_transfer_except_%s.pickle.dat\" % ('PCI', model_name, s), \"wb\"))\n",
    "    \n",
    "for x in nrmse_matrix[model_idx, 2, 1:]:\n",
    "    print('%.3f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = ['baseline', 'independent', 'transfer']\n",
    "for scenario in range(3) :\n",
    "    print(\"========================================\"+scenarios[scenario])\n",
    "    baseline_metrics = nrmse_matrix[:, scenario, 1:]\n",
    "    baseline_metrics = baseline_metrics[~np.isnan(baseline_metrics)].reshape((4,len(sets)))\n",
    "    print('avg of each methods', np.mean(baseline_metrics, axis=1))\n",
    "    print('best performance', np.unique(np.argmin(baseline_metrics, axis=0), return_counts=True))\n",
    "    \n",
    "    print('diff performance')\n",
    "    min_list = np.min(baseline_metrics, axis=0)\n",
    "\n",
    "    for x in baseline_metrics :\n",
    "        diff = x-min_list\n",
    "        print(np.mean(diff[np.nonzero(diff)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for curr_model in range(4) :\n",
    "    print(\"========================================\"+model_name_list[curr_model])\n",
    "    metrics = nrmse_matrix[curr_model, :, 1:]\n",
    "    metrics = metrics[~np.isnan(metrics)].reshape((3,len(sets)))\n",
    "    print('avg of each scenario', np.mean(metrics, axis=1))\n",
    "    print('best performance', np.unique(np.argmin(metrics, axis=0), return_counts=True))\n",
    "    \n",
    "    baseline_metrics = nrmse_matrix[curr_model, 0, 1:]\n",
    "    for i in range(1, 3) :\n",
    "        print(scenarios[i])\n",
    "        curr_metrics = nrmse_matrix[curr_model, i, 1:]\n",
    "        drop_idx = curr_metrics > baseline_metrics\n",
    "        diff = baseline_metrics[drop_idx] - curr_metrics[drop_idx]\n",
    "        print('-------decrease ', i, len(diff), np.mean(diff))\n",
    "        \n",
    "        improve_idx = curr_metrics < baseline_metrics\n",
    "        diff = baseline_metrics[improve_idx] - curr_metrics[improve_idx]\n",
    "        print('+++++++increase ', i, len(diff), np.mean(diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Predicted Coordinate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cut = 50  \n",
    "y_cut = 100 \n",
    "\n",
    "old_origin_img = cv2.imread('../image/map.png',0)\n",
    "crop = old_origin_img[y_cut:318, x_cut:927]\n",
    "crop = cv2.cvtColor(crop, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "x_coord_list = []\n",
    "y_coord_list = []\n",
    "pci_list = []\n",
    "for lon in range(0, crop.shape[1]) :\n",
    "    for lat in range(0, crop.shape[0]) :\n",
    "        x_coord_list.append(x_cut + lon)\n",
    "        y_coord_list.append(y_cut + lat)\n",
    "        \n",
    "all_x_pci = pd.DataFrame({'location_x':x_coord_list, 'location_y':y_coord_list})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Opt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import gridspec\n",
    "\n",
    "loc_df = pci_data[['location_x', 'location_y', 'PCI']]\n",
    "def get_pci(x, y) :\n",
    "    distance = lambda d: math.hypot(abs(x-d[0]), abs(y-d[1]))\n",
    "    loc_df[\"d\"] = loc_df.apply(distance, axis=1)\n",
    "    return loc_df.loc[loc_df.d.idxmin()].PCI\n",
    "\n",
    "class target() :\n",
    "    def optimize(self, x, y) :\n",
    "        if self.bayes_opt is None or self.bayes_opt.X is None:\n",
    "            return 1000\n",
    "\n",
    "        bo = self.bayes_opt\n",
    "        bo.gp.fit(bo.X, bo.Y)\n",
    "        mu, sigma = bo.gp.predict(all_x_pci.values, return_std=True)\n",
    "        return -mean(sigma)\n",
    "\n",
    "def posterior(bo, x):\n",
    "    bo.gp.fit(bo.X, bo.Y)\n",
    "    mu, sigma = bo.gp.predict(x, return_std=True)\n",
    "    plot(sigma)\n",
    "    plt.show()\n",
    "    return mu, sigma\n",
    "\n",
    "def plot_gp(bo, x, curr_x_train, curr_y_train, set_val, model, show_sigma_map=False):\n",
    "    path = \"../results/predicted/pci/real_%s_set_%d.png\" % (model, set_val)\n",
    "    background = get_map_image()\n",
    "    p_color = [pci_decode[y] for y in curr_y_train]\n",
    "    p_color = [pci_color_dict[y] if y in pci_color_dict else (255, 255, 255) for y in p_color]\n",
    "    b = visualize(background, curr_x_train['location_x'].astype(int), curr_x_train['location_y'].astype(int), \n",
    "                  p_color, path, adjustment=True)\n",
    "\n",
    "    if show_sigma_map :\n",
    "        normalize_sigma = matplotlib.colors.Normalize(vmin=min(sigma), vmax=max(sigma))\n",
    "        mu_map = [cmap(normalize_sigma(value))[:3] for value in mu_sigma]\n",
    "        mu_map = [[int(x*255) for x in value] for value in mu_map]    \n",
    "        a=visualize_all_location_heatmap(a, x_coord_view, y_coord_view, mu_map, \n",
    "                                         cmap, normalize_sigma, filename=None,\n",
    "                                         size=1, figsize=(20,10), adjustment=False, show=False)\n",
    "    \n",
    "def get_target(model_name, curr_x_train, curr_y_train, curr_x_test, curr_y_test) :\n",
    "    if 'xgb' in model_name : \n",
    "        return xgboost_target(curr_x_train, curr_y_train, curr_x_test, curr_y_test)\n",
    "    elif 'knn' in model_name : \n",
    "        return knn_target(curr_x_train, curr_y_train, curr_x_test, curr_y_test)\n",
    "    else : \n",
    "        return lgbm_target(curr_x_train, curr_y_train, curr_x_test, curr_y_test)\n",
    "    \n",
    "def get_params_range(model_name) :\n",
    "    if 'xgb' in model_name : \n",
    "        return {'learning_rate': (1, 12),\n",
    "                'booster' : (1, 3),\n",
    "                'gamma' : (0, 5),\n",
    "                'max_depth': (3, 10),\n",
    "                'min_child_weight': (1, 1),\n",
    "                'max_delta_weight': (1, 12),\n",
    "                'rate_drop': (0, 1)}\n",
    "    elif 'knn' in model_name : \n",
    "        return {'weight': (0, 1),\n",
    "                'algorithm' : (0, 3),\n",
    "                'leaf_size' : (5, 50),\n",
    "                'p': (1, 2),}\n",
    "    else :\n",
    "        return {'min_child_weight': (0.01, 1),\n",
    "              'learning_rate': (1, 10),\n",
    "              'max_depth': (-1, 15),\n",
    "              'num_leaves': (5, 50)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random = 0\n",
    "t = target()\n",
    "bo2 = BayesianOptimization(t.optimize, {'x': (min(x_coord_list), max(x_coord_list)), \n",
    "                                        'y': (min(y_coord_list), max(y_coord_list))},\n",
    "                           random_state=random, \n",
    "                           verbose=1)\n",
    "t.bayes_opt = bo2\n",
    "\n",
    "iterations = 100\n",
    "gp_params = {\"alpha\": 1e-5, \"n_restarts_optimizer\": 3, 'random_state':random}\n",
    "bo2.maximize(init_points=2, n_iter=iterations, acq=\"ei\", xi=0.1, **gp_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random = 3\n",
    "t = target()\n",
    "bo3 = BayesianOptimization(t.optimize, {'x': (min(x_coord_list), max(x_coord_list)), \n",
    "                                        'y': (min(y_coord_list), max(y_coord_list))},\n",
    "                           random_state=random, \n",
    "                           verbose=1)\n",
    "t.bayes_opt = bo3\n",
    "\n",
    "iterations = 500\n",
    "gp_params = {\"alpha\": 1e-5, \"n_restarts_optimizer\": 3, 'random_state':random}\n",
    "bo3.maximize(init_points=10, n_iter=iterations, acq=\"ei\", xi=1e+1, **gp_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Independent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc_dict = {}\n",
    "for set_val in demo_config[6] :\n",
    "    curr_pci_data = pci_data[pci_data.set == set_val]\n",
    "    iterations = int(0.2*len(curr_pci_data)) + 5\n",
    "\n",
    "    temp = curr_pci_data.copy()\n",
    "    temp2 = pd.DataFrame(columns=temp.columns)\n",
    "    for x in bo3.X[:iterations] :\n",
    "        distance = lambda d: math.hypot(abs(x[0]-d[0]), abs(x[1]-d[1]))\n",
    "        temp[\"d\"] = temp.apply(distance, axis=1)\n",
    "        temp2 = temp2.append(temp.loc[temp.d.idxmin()])\n",
    "\n",
    "    temp3 = curr_pci_data[~curr_pci_data.index.isin(temp2.index)]\n",
    "\n",
    "    curr_x_train = temp2.drop([\"PCI\", \"d\"], axis=1)\n",
    "    curr_y_train = temp2.PCI.apply(lambda x : pci_encode[x]).values.tolist()\n",
    "    curr_x_test = temp3.drop(\"PCI\", axis=1)\n",
    "    curr_y_test = temp3.PCI.apply(lambda x : pci_encode[x]).values.tolist()\n",
    "\n",
    "#     plot_gp(bo2, all_x_pci.values, curr_x_train, curr_y_train, set_val, \"xgboost\")\n",
    "    \n",
    "#     params = {'learning_rate' : 0.03, 'max_depth' : 9, 'min_child_weight':1, 'gamma':4.2522, \n",
    "#               'max_delta_weight':11, 'random_state' :random}\n",
    "#     params = {'learning_rate' : 0.03, 'max_depth' : 9, 'min_child_weight':1, 'gamma':1, \n",
    "#               'max_delta_weight':11, 'random_state' :random}\n",
    "\n",
    "#     t = get_target(model_name, curr_x_train, curr_y_train, curr_x_test, curr_y_test)\n",
    "#     xgbBO = BayesianOptimization(t.evaluate, \n",
    "#                                  get_params_range(model_name),\n",
    "#                                  random_state = random, \n",
    "#                                  verbose=0)\n",
    "\n",
    "#     xgbBO.maximize(init_points=5, n_iter=3)\n",
    "#     print(xgbBO.res['max']['max_params'])\n",
    "#     params = t.clean_param(xgbBO.res['max']['max_params'])\n",
    "\n",
    "    params = lgbm_params\n",
    "    params['min_data_in_bin']=1\n",
    "    params['min_data']=1\n",
    "    \n",
    "    model = reset_model(model_name, params)\n",
    "    model.fit(curr_x_train, curr_y_train)\n",
    "    pickle.dump(model, open(\"db/%s_%s_bayesian_independent_%s.pickle.dat\" % \\\n",
    "                            ('PCI', model_name, set_val), \"wb\"))\n",
    "\n",
    "# for set_val in demo_config[6] :\n",
    "    y_pci_pred = model.predict(curr_x_test)\n",
    "    predictions = [round(value) for value in y_pci_pred]\n",
    "    accuracy = accuracy_score(curr_y_test, predictions)\n",
    "    acc_dict[set_val] = [len(curr_x_train), len(curr_x_test), accuracy]\n",
    "    print(1-accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgbm, random state 0 \n",
    "bayes_inden = np.array([x for x in acc_dict.values()])\n",
    "for x in list(bayes_inden[:, 2]) :\n",
    "    print(1-x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "acc_dict = {}\n",
    "all_curr_x_train, all_curr_y_train = pd.DataFrame(), []\n",
    "all_curr_x_test, all_curr_y_test = pd.DataFrame(), []\n",
    "all_curr_x_test_dict, all_curr_y_test_dict = {}, {}\n",
    "for set_val in demo_config[6] :\n",
    "    curr_pci_data = pci_data[pci_data.set == set_val]\n",
    "    iterations = int(0.2*len(curr_pci_data))\n",
    "\n",
    "    temp = curr_pci_data.copy()\n",
    "    temp2 = pd.DataFrame(columns=temp.columns)\n",
    "    for x in bo3.X[:iterations] :\n",
    "        distance = lambda d: math.hypot(abs(x[0]-d[0]), abs(x[1]-d[1]))\n",
    "        temp[\"d\"] = temp.apply(distance, axis=1)\n",
    "        temp2 = temp2.append(temp.loc[temp.d.idxmin()])\n",
    "\n",
    "    temp3 = curr_pci_data[~curr_pci_data.index.isin(temp2.index)]\n",
    "\n",
    "    curr_x_train = temp2.drop([\"PCI\", \"d\"], axis=1)\n",
    "    curr_y_train = temp2.PCI.apply(lambda x : pci_encode[x]).values.tolist()\n",
    "    curr_x_test = temp3.drop(\"PCI\", axis=1)\n",
    "    curr_y_test = temp3.PCI.apply(lambda x : pci_encode[x]).values.tolist()\n",
    "\n",
    "    all_curr_x_train = all_curr_x_train.append(curr_x_train)\n",
    "    all_curr_y_train += curr_y_train \n",
    "    all_curr_x_test = all_curr_x_test.append(curr_x_test)\n",
    "    all_curr_y_test += curr_y_test\n",
    "    all_curr_x_test_dict[set_val] = curr_x_test\n",
    "    all_curr_y_test_dict[set_val] = curr_y_test  \n",
    "\n",
    "#     plot_gp(bo2, all_x_pci.values, curr_x_train, curr_y_train, set_val, \"xgboost\")\n",
    "    \n",
    "#     params = {'learning_rate' : 0.03, 'max_depth' : 9, 'min_child_weight':1, 'gamma':4.2522, \n",
    "#               'max_delta_weight':11, 'random_state' :random}\n",
    "#     params = {'learning_rate' : 0.03, 'max_depth' : 9, 'min_child_weight':1, 'gamma':1, \n",
    "#               'max_delta_weight':11, 'random_state' :random}\n",
    "\n",
    "t = get_target(model_name, curr_x_train, curr_y_train, curr_x_test, curr_y_test)\n",
    "xgbBO = BayesianOptimization(t.evaluate, \n",
    "                             get_params_range(model_name),\n",
    "                             random_state = random, \n",
    "                             verbose=1)\n",
    "\n",
    "xgbBO.maximize(init_points=5, n_iter=15)\n",
    "print(xgbBO.res['max']['max_params'])\n",
    "params = t.clean_param(xgbBO.res['max']['max_params'])\n",
    "\n",
    "# params = lgbm_params\n",
    "params['min_data_in_bin']=1\n",
    "params['min_data']=1\n",
    "    \n",
    "model = reset_model(model_name, params)\n",
    "model.fit(curr_x_train, curr_y_train)\n",
    "pickle.dump(model, open(\"db/%s_%s_bayesian_baseline_%s.pickle.dat\" % ('PCI', model_name, set_val), \"wb\"))\n",
    "\n",
    "for set_val in demo_config[6] :\n",
    "    y_pci_pred = model.predict(all_curr_x_test_dict[set_val])\n",
    "    predictions = [round(value) for value in y_pci_pred]\n",
    "    accuracy = accuracy_score(all_curr_y_test_dict[set_val], predictions)\n",
    "    acc_dict[set_val] = [len(curr_x_train), len(curr_x_test), accuracy]\n",
    "    print(1-accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgbm, random state 0 \n",
    "bayes_baseline = np.array([x for x in acc_dict.values()])\n",
    "for x in list(bayes_baseline[:, 2]) :\n",
    "    print(1-x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Transfer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_dict = {}\n",
    "all_curr_x_train_dict, all_curr_y_train_dict = {}, {}\n",
    "all_curr_x_test_dict, all_curr_y_test_dict = {}, {}\n",
    "for set_val in demo_config[6] :\n",
    "    curr_pci_data = pci_data[pci_data.set == set_val]\n",
    "    iterations = int(0.7*len(curr_pci_data)) + 5\n",
    "\n",
    "    temp = curr_pci_data.copy()\n",
    "    temp2 = pd.DataFrame(columns=temp.columns)\n",
    "    for x in bo3.X[:iterations] :\n",
    "        distance = lambda d: math.hypot(abs(x[0]-d[0]), abs(x[1]-d[1]))\n",
    "        temp[\"d\"] = temp.apply(distance, axis=1)\n",
    "        temp2 = temp2.append(temp.loc[temp.d.idxmin()])\n",
    "\n",
    "    curr_x_train = temp2.drop([\"PCI\", \"d\"], axis=1)\n",
    "    curr_y_train = temp2.PCI.apply(lambda x : pci_encode[x]).values.tolist()\n",
    " \n",
    "    all_curr_x_train_dict[set_val] = curr_x_train\n",
    "    all_curr_y_train_dict[set_val] = curr_y_train  \n",
    "    all_curr_x_test_dict[set_val] = curr_pci_data.drop(\"PCI\", axis=1)\n",
    "    all_curr_y_test_dict[set_val] = curr_pci_data.PCI.apply(lambda x : pci_encode[x]).values.tolist()\n",
    "#     print(set_val, len(curr_x_train), len(curr_x_test))\n",
    "\n",
    "#     plot_gp(bo2, all_x_pci.values, curr_x_train, curr_y_train, set_val, \"xgboost\")\n",
    "    \n",
    "#     params = {'learning_rate' : 0.03, 'max_depth' : 9, 'min_child_weight':1, 'gamma':4.2522, \n",
    "#               'max_delta_weight':11, 'random_state' :random}\n",
    "#     params = {'learning_rate' : 0.03, 'max_depth' : 9, 'min_child_weight':1, 'gamma':1, \n",
    "#               'max_delta_weight':11, 'random_state' :random}\n",
    "\n",
    "#     t = get_target(model_name, all_curr_x_train, all_curr_y_train, all_curr_x_test, all_curr_y_test)\n",
    "#     xgbBO = BayesianOptimization(t.evaluate, \n",
    "#                                  get_params_range(model_name),\n",
    "#                                  random_state = random, \n",
    "#                                  verbose=0)\n",
    "\n",
    "#     xgbBO.maximize(init_points=5, n_iter=3)\n",
    "#     print(xgbBO.res['max']['max_params'])\n",
    "#     params = t.clean_param(xgbBO.res['max']['max_params'])\n",
    "\n",
    "    params = lgbm_params\n",
    "    params['min_data_in_bin']=1\n",
    "    params['min_data']=1\n",
    "    \n",
    "for set_val in demo_config[6] :\n",
    "    curr_x_train, curr_y_train = pd.DataFrame(), []\n",
    "    for k in all_curr_x_train_dict :\n",
    "        if k != set_val :\n",
    "            curr_x_train = curr_x_train.append(all_curr_x_train_dict[k])\n",
    "            curr_y_train += all_curr_y_train_dict[k]\n",
    "    \n",
    "    model = reset_model(model_name, params)\n",
    "    model.fit(curr_x_train, curr_y_train)\n",
    "    pickle.dump(model, open(\"db/%s_%s_bayesian_transfer_%s.pickle.dat\" % ('PCI', model_name, set_val), \"wb\"))\n",
    "\n",
    "    y_pci_pred = model.predict(all_curr_x_test_dict[set_val])\n",
    "    predictions = [round(value) for value in y_pci_pred]\n",
    "    accuracy = accuracy_score(all_curr_y_test_dict[set_val], predictions)\n",
    "    acc_dict[set_val] = [len(curr_x_train), len(all_curr_y_test_dict[set_val]), accuracy]\n",
    "    print(1-accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgbm, random state 0 \n",
    "bayes_transfer = np.array([x for x in acc_dict.values()])\n",
    "for x in list(bayes_transfer[:, 2]) :\n",
    "    print(1-x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
